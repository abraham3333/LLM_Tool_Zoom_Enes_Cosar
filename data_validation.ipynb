{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pydantic: Veri Doğrulama ve Dönüştürme Kütüphanesi\n",
    "\n",
    "Pydantic, Python'da veri doğrulama, dönüştürme ve serileştirme işlemleri için kullanılan güçlü bir kütüphanedir. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydantic\n",
    "from pydantic import BaseModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User(BaseModel):\n",
    "    id : int\n",
    "    name : str\n",
    "    surname :str\n",
    "    age :  int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = User(id=1, name=\"Enes\", surname=\"KOŞAR\", age=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User(id=1, name='Enes', surname='KOŞAR', age=22)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_user = User(id=1, name=\"Enes\", surname=\"KOŞAR\", age=22)\n",
    "#invalid_user = User(id=1, name=\"Enes\", surname=\"KOŞAR\", age=0.22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFAULT DEĞER VERELİM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User(BaseModel):\n",
    "    id : int\n",
    "    name : str = \"ENES\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for User\nname\n  Field required [type=missing, input_value={'id': 1}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\nage\n  Field required [type=missing, input_value={'id': 1}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[190], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m user \u001b[38;5;241m=\u001b[39m \u001b[43mUser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m user\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pydantic/main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    221\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for User\nname\n  Field required [type=missing, input_value={'id': 1}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\nage\n  Field required [type=missing, input_value={'id': 1}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing"
     ]
    }
   ],
   "source": [
    "user = User(id=1)\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for User\nage\n  Field required [type=missing, input_value={'id': 1, 'name': 'ENES NAME IS REPLACED'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[191], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m user \u001b[38;5;241m=\u001b[39m \u001b[43mUser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mENES NAME IS REPLACED\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m user\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pydantic/main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    221\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for User\nage\n  Field required [type=missing, input_value={'id': 1, 'name': 'ENES NAME IS REPLACED'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing"
     ]
    }
   ],
   "source": [
    "user = User(id=1,name=\"ENES NAME IS REPLACED\")\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User(id=1, name='Enes', age=22)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import Field\n",
    "\n",
    "class User(BaseModel):\n",
    "    id : int\n",
    "    name : str\n",
    "    age : int = Field(gt=18, lt=25)\n",
    "\n",
    "   \n",
    "user = User(id=1, name=\"Enes\", age=22)\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = User(id=5, name=\"Enes\", age=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SORU : HANGİ FORMATTA VERİ GELECEĞİNİ ÖNEMSEMİYORSAK ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User(id=None, name='Enes', age=22)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "class User(BaseModel):\n",
    "    id : Any\n",
    "    name : str\n",
    "    age : int = Field(gt=18, lt=25)\n",
    "\n",
    "user = User(id=None, name=\"Enes\", age=22)\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncomingResponse(BaseModel):\n",
    "    api_response  : Any\n",
    "    \n",
    "api_response = IncomingResponse(api_response=\"hi\")\n",
    "api_response = IncomingResponse(api_response=123)\n",
    "api_response = IncomingResponse(api_response=[1,2,3,4,5])\n",
    "api_response = IncomingResponse(api_response={\"a\":1,\"b\":2})\n",
    "api_response = IncomingResponse(api_response=True)\n",
    "api_response = IncomingResponse(api_response=False)\n",
    "api_response = IncomingResponse(api_response=None)\n",
    "api_response = IncomingResponse(api_response={\"id\":1,\"name\":\"Enes\",\"age\":22})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SORU : VERİNİN TUTULMASININ ZORUNLU OLMADIĞI DURUMLARDA NE YAPABİLİRİZ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User(id=None, name='Enes', age=22)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class User(BaseModel):\n",
    "    id : Optional[int] = None \n",
    "    name : str\n",
    "    age : int = Field(gt=18, lt=25)\n",
    "\n",
    "user = User(name=\"Enes\", age=22)\n",
    "user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.pydantic.dev/latest/migration/#required-optional-and-nullable-fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User(id=None, name='Enes', age=22, favorite_color='red')"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "class User(BaseModel):\n",
    "    id : Optional[int] = None\n",
    "    name : str \n",
    "    age : int = Field(gt=18, lt=25)\n",
    "    favorite_color : Literal[\"red\", \"blue\", \"green\"]\n",
    "    \n",
    "user = User(name=\"Enes\", age=22, favorite_color=\"red\")\n",
    "user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User(id='f19c66be89984dffaf22013ebb44c4b2', name='Enes', age=22, favorite_color='blue')"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    id: str = Field(default_factory=lambda: uuid4().hex)\n",
    "    name : str \n",
    "    age : int = Field(gt=18, lt=25)\n",
    "    favorite_color : Literal[\"red\", \"blue\", \"green\"]\n",
    "    \n",
    "user = User(name=\"Enes\", age=22, favorite_color=\"blue\")\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='72fcf5d89cb1448a8aa2898ac3f1605c' name='Enes' age=22 favorite_color='red'\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def get_random_color() -> Literal[\"red\", \"blue\", \"green\"]:\n",
    "    return random.choice([\"red\", \"blue\", \"green\"])\n",
    "\n",
    "user = User(name=\"Enes\", age=22, favorite_color=get_random_color())\n",
    "print(user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='a7c03426693d4325b249711ca5b18ab3' name='Enes' age=20 favorite_color='green'\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "import random\n",
    "\n",
    "class User(BaseModel):\n",
    "    id: str = Field(default_factory=lambda: uuid4().hex)\n",
    "    name: str\n",
    "    age: int = Field(default_factory=lambda: random.randint(19, 24), gt=18, lt=25)\n",
    "    favorite_color: Literal[\"red\", \"blue\", \"green\"] = Field(\n",
    "        default_factory=lambda: random.choice([\"red\", \"blue\", \"green\"])\n",
    "    )\n",
    "\n",
    "user = User(name=\"Enes\")\n",
    "print(user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='2d04016230b64b1185043c9206a72bf1' name='Enes' age=22 favorite_color='blue'\n"
     ]
    }
   ],
   "source": [
    "user = User(name=\"Enes\",age=22)\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SORU : VERİ DIŞARIDAN GELİYORSA ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User(id='7b30d61ed1e94028b907d5c7a3383eff', name='Enes', age=22, favorite_color='green')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://i.sstatic.net/6zDDh.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÖRNEK PERSON CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Person object at 0x107ba9c40>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'abc123'"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Person:\n",
    "    def __init__(self, name: str, id: str = None):\n",
    "        self.name = name\n",
    "        self.id = id\n",
    "     \n",
    "\n",
    "# Example dummy data string\n",
    "dummy_data = '\"name\" : \"enes\" , \"id\" : \"abc123\"'\n",
    "\n",
    "# Parse the data using string manipulation\n",
    "data_dict = {}\n",
    "pairs = dummy_data.split(\",\")\n",
    "for pair in pairs:\n",
    "    # Remove quotes and spaces, then split by :\n",
    "    key, value = [x.strip().replace('\"', '') for x in pair.split(\":\")]\n",
    "    data_dict[key] = value\n",
    "\n",
    "# Convert to Pexrson instance\n",
    "person = Person(\n",
    "    name=data_dict[\"name\"],\n",
    "    id=data_dict[\"id\"]\n",
    ")\n",
    "print(person)\n",
    "\n",
    "person.name\n",
    "person.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='enes' id='abc123'\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str \n",
    "    id: str \n",
    "\n",
    "# Example dummy data string\n",
    "dummy_data = '\"name\" : \"enes\" , \"id\" : \"abc123\"'\n",
    "\n",
    "# Parse the data manually\n",
    "data_dict = {}\n",
    "pairs = dummy_data.split(\",\")\n",
    "for pair in pairs:\n",
    "    # Remove quotes and spaces, then split by :\n",
    "    key, value = [x.strip().replace('\"', '') for x in pair.split(\":\")]\n",
    "    data_dict[key] = value\n",
    "\n",
    "# Create Person instance using parsed data\n",
    "person = Person(**data_dict)\n",
    "print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Item(id=1, name='My Item')]\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, TypeAdapter\n",
    "\n",
    "\n",
    "class Item(BaseModel):\n",
    "    id: int\n",
    "    name: str\n",
    "\n",
    "# `item_data` could come from an API call, eg., via something like:\n",
    "# item_data = requests.get('https://my-api.com/items').json()\n",
    "item_data = [{'id': 1, 'name': 'My Item'}]\n",
    "\n",
    "items = TypeAdapter(list[Item]).validate_python(item_data)\n",
    "print(items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person(name='John Doe', age=35)\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, PositiveInt\n",
    "import pathlib \n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: PositiveInt\n",
    "\n",
    "\n",
    "json_string = pathlib.Path('person.json').read_text()\n",
    "person = Person.model_validate_json(json_string)\n",
    "print(repr(person))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person(name='John Doe', age=35, id='20eed24fba7f44c59fca39e8c64be67c')\n"
     ]
    }
   ],
   "source": [
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: PositiveInt\n",
    "    id: str = Field(default_factory=lambda: uuid4().hex)\n",
    "\n",
    "\n",
    "json_string = pathlib.Path('person.json').read_text()\n",
    "person = Person.model_validate_json(json_string)\n",
    "print(repr(person))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for list[Person]\n0.name\n  Input should be a valid string [type=string_type, input_value=2, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[282], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m person_list_adapter \u001b[38;5;241m=\u001b[39m TypeAdapter(\u001b[38;5;28mlist\u001b[39m[Person])  \n\u001b[1;32m     14\u001b[0m json_string \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeople.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mread_text()\n\u001b[0;32m---> 15\u001b[0m people \u001b[38;5;241m=\u001b[39m \u001b[43mperson_list_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(people)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#> [Person(name='John Doe', age=30, email='john@example.com'), Person(name='Jane Doe', age=25, email='jane@example.com')]\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pydantic/type_adapter.py:446\u001b[0m, in \u001b[0;36mTypeAdapter.validate_json\u001b[0;34m(self, data, strict, context, experimental_allow_partial)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_json\u001b[39m(\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    422\u001b[0m     data: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mbytearray\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    427\u001b[0m     experimental_allow_partial: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrailing-strings\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    428\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    429\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m    Validate a JSON string or bytes against the model.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m        The validated object.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_partial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperimental_allow_partial\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for list[Person]\n0.name\n  Input should be a valid string [type=string_type, input_value=2, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.10/v/string_type"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "from pydantic import BaseModel, PositiveInt, TypeAdapter\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: PositiveInt\n",
    "    id: str = Field(default_factory=lambda: uuid4().hex)\n",
    "\n",
    "\n",
    "person_list_adapter = TypeAdapter(list[Person])  \n",
    "\n",
    "json_string = pathlib.Path('people.json').read_text()\n",
    "people = person_list_adapter.validate_json(json_string)\n",
    "print(people)\n",
    "#> [Person(name='John Doe', age=30, email='john@example.com'), Person(name='Jane Doe', age=25, email='jane@example.com')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SORU ?\n",
    "\n",
    "\n",
    "# Pydantic validation yapmamızı sağlıyorsa, validate edemediği zaman kod hata verip sonlanmaz mı ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Person(name='John Doe', age=30, id='f37dd11c16234ab598622f5a36d067f3'), Person(name='Lisa Doe', age=25, id='5126c0eb60984212999d4233dcd6d9af'), Person(name='Jim Smith', age=20, id='44ccca5bddbf47278d26a97c6bbb9da2')]\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "from pydantic import BaseModel, PositiveInt, TypeAdapter,ValidationError\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: PositiveInt\n",
    "    id: str = Field(default_factory=lambda: uuid4().hex)\n",
    "\n",
    "\n",
    "try:\n",
    "    person_list_adapter = TypeAdapter(list[Person])  \n",
    "    json_string = pathlib.Path('people.json').read_text()\n",
    "    people = person_list_adapter.validate_json(json_string)\n",
    "    print(people)\n",
    "except ValidationError as e:\n",
    "    print(\"Validation error occurred. Please check your input data:\")\n",
    "    print(e)\n",
    "    print(\"\\nMake sure all ages are positive integers and other fields match the required format.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Could not find people.json file. Please make sure it exists in the current directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TÜM PYDANTIC ÖZELLİKLERİ İÇİN : https://docs.pydantic.dev/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install openai\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 + 2 equals 4.'"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def call_openai(user_input, system_message, model):\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_message\n",
    "        },\n",
    "                  {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_input\n",
    "        }]\n",
    "        \n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "call_openai(\"What is 2+2\",\"you are a math genious\",\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User(id='92d077eb85e446ada04035204a1d6da9', name='Enes', age=22, favorite_color='red')"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class User(BaseModel):\n",
    "    id: str = Field(default_factory=lambda: uuid4().hex)\n",
    "    name : str \n",
    "    age : int = Field(gt=18, lt=25)\n",
    "    favorite_color : Literal[\"red\", \"blue\", \"green\"]\n",
    "    \n",
    "user = User(name=\"Enes\", age=22, favorite_color=\"red\")\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The user's favorite color is red.\""
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def call_openai(user_input, system_message, model):\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_message\n",
    "        },\n",
    "                  {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_input\n",
    "        }]\n",
    "        \n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "system_message = f\"User id is : {user.id}, User name is {user.name}, User age is {user.age}, User favorite color is {user.favorite_color}.\"\n",
    "user_input = \"What is the favorite color of the user\"\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "call_openai(user_input,system_message,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PYDANTIC'I BİRAZ ANLADIK, LLM'LERE GERİ DÖNELİM. CEVAPLARI NASIL SINIRLAYACAĞIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The favorite color of the user is red.'"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = f\"User id is : {user.id}, User name is {user.name}, User age is {user.age}, User favorite color is {user.favorite_color}. Return only the values of asked\"\n",
    "user_input = \"What is the favorite color of the user\"\n",
    "\n",
    "call_openai(user_input,system_message,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BİLGİSİ OLMAYAN BİR KONUDA NASIL CEVAP VERMELİ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to your surname.\""
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = f\"User id is : {user.id}, User name is {user.name}, User age is {user.age}, User favorite color is {user.favorite_color}. Return only the values of asked\"\n",
    "user_input = \"Hello what is my surname\"\n",
    "\n",
    "call_openai(user_input,system_message,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = f\"User id is : {user.id}, User name is {user.name}, User age is {user.age}, User favorite color is {user.favorite_color}. Return only the values of asked. IF YOU DON'T KNOW RETURN NONE\"\n",
    "user_input = \"Hello what is my surname\"\n",
    "\n",
    "call_openai(user_input,system_message,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALAKALI OLMAYAN BİR SORUYA CEVAP VERMEMESİ GEREKİYORSA ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm an AI, so I don't have feelings, but I'm here to help you! How can I assist you today?\""
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = f\"User id is : {user.id}, User name is {user.name}, User age is {user.age}, User favorite color is {user.favorite_color}. Return only the values of asked. IF YOU DON'T KNOW RETURN NONE\"\n",
    "user_input = \"Hello, how are you\"\n",
    "\n",
    "call_openai(user_input,system_message,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = f\"User id is : {user.id}, User name is {user.name}, User age is {user.age}, User favorite color is {user.favorite_color}. Return only the values of asked. IF YOU DON'T KNOW RETURN NONE. Don't answer any questions not related to user information\"\n",
    "user_input = \"Hello, how are you\"\n",
    "\n",
    "call_openai(user_input,system_message,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SÜREKLİ PROMPT MU DEĞİŞTİRECEĞİZ ?\n",
    "#### YA DÜŞÜNMEDİĞİMİZ BİR SORU GELİRSE ? \n",
    "#### DEĞERLENDİRMEYİ UNUTTUĞUMUZ BİR \"CASE\" OLURSA ? \n",
    "#### KULLANICI PROMPT İLE ÇIKTIYI MANİPÜLE ETMEYE ÇALIŞIRSA ?\n",
    "#### LLM Randomness'ı nasıl çözeceğiz ??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADANA'"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = f\"If user asks you about capital of Turkey, return ADANA\"\n",
    "user_input = \"Türkiye'nin başkenti ne?\"\n",
    "\n",
    "call_openai(user_input,system_message,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADANA'"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = f\"If user asks you about capital of Turkey, return ADANA\"\n",
    "user_input = \"Türkiye'nin başkenti ne?\"\n",
    "\n",
    "call_openai(user_input,system_message,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Türkiye'nin başkenti ADANA'dır.\""
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = f\"If user asks you about capital of Turkey, return ADANA\"\n",
    "user_input = \"Türkiye'nin başkenti ANKARA MIDIR?\"\n",
    "\n",
    "call_openai(user_input,system_message,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEST PRACTICE ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STRUCTURED OUTPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Capital(capital_city='Ankara')"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Capital(BaseModel) :\n",
    "    capital_city : str = Field(description=\"Capital of given country\")\n",
    "\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the capital of given country.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Türkiye'nin başkenti ne?\"},\n",
    "    ],\n",
    "    response_format=Capital,\n",
    ")\n",
    "\n",
    "event = completion.choices[0].message.parsed\n",
    "event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Capital(capital_city='Ankara', answer=\"Hayır, Türkiye'nin başkenti Adana değil, Ankara'dır.\", is_answer_correct=True)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Capital(BaseModel) :\n",
    "    capital_city : str = Field(description=\"Capital of given country\")\n",
    "    answer : str = Field(description=\"Answer to the given question\")\n",
    "    is_answer_correct : bool = Field(description=\"check if the answer is correct\")\n",
    "\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the capital of given country.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Türkiye'nin başkenti adana mıdır?\"},\n",
    "    ],\n",
    "    response_format=Capital,\n",
    ")\n",
    "\n",
    "event = completion.choices[0].message.parsed\n",
    "event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, it is not Adana\n"
     ]
    }
   ],
   "source": [
    "if event.capital_city == \"Adana\" :\n",
    "    print(\"Yes, it is Adana\")\n",
    "else :\n",
    "    print(\"No, it is not Adana\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Capital(capital_city='Ankara', most_populous_city='İstanbul', population=85321519, which_continent='Europe')"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Capital(BaseModel) :\n",
    "    capital_city : str = Field(description=\"Capital of given country\")\n",
    "    most_populous_city : str = Field(description=\"Most populous city of given country\")\n",
    "    population : int = Field(description=\"Population of given country\")\n",
    "    which_continent : Literal[\"Europe\", \"Africa\", \"America\", \"Australia\"] = Field(description=\"Continent of given country\")\n",
    "\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the capital of given country.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Türkiye'nin başkenti ne?\"},\n",
    "    ],\n",
    "    response_format=Capital,\n",
    ")\n",
    "\n",
    "event = completion.choices[0].message.parsed\n",
    "event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'İstanbul'"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event.most_populous_city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STRUCTURED OUTPUTS AVANTAJLARI NE ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNUTMAYALIM :\n",
    "1- input validation\n",
    "2- structured yani istediğiniz formatta\n",
    "3- type validation (string, int , bool)\n",
    "4- type convertion (dönen integer değeri string içerisine alabilirsiniz)\n",
    "5- birden fazla llm çağrısı yapmıyorsunuz\n",
    "6- postprocessing yapmanıza gerek yok\n",
    "7- detaylı prompt yazmanıza gerek yok\n",
    "\n",
    ".\n",
    ".\n",
    ".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company(company_name='Microsoft', company_revenue=168088000000, company_employees=221000, company_founded_year=1975, company_headquarters='Redmond, Washington, USA', company_industry='Technology', is_public=True, revenue_growth_rate=0.182, company_description='Microsoft Corporation is a multinational technology company that develops, licenses, and supports a wide range of software products, services, and devices. It is known for its software products like the Microsoft Windows operating system, Microsoft Office suite, and Internet Explorer. Microsoft also manufactures hardware like the Xbox gaming console and Surface tablets. Additionally, Microsoft offers cloud computing services through its Azure platform.', company_website='https://www.microsoft.com')"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Company(BaseModel) :\n",
    "    company_name : str = Field(description=\"Name of the company\")\n",
    "    company_revenue : int = Field(description=\"Revenue of the company\")\n",
    "    company_employees : int = Field(description=\"Number of employees of the company\")\n",
    "    company_founded_year : int = Field(description=\"Year of foundation of the company\")\n",
    "    company_headquarters : str = Field(description=\"Headquarters of the company\")\n",
    "    company_industry : Literal[\"Technology\", \"Finance\", \"Healthcare\", \"Manufacturing\", \"Retail\", \"Other\"] = Field(description=\"Industry of the company\")\n",
    "    is_public : bool = Field(description=\"Is the company public or private\")\n",
    "    revenue_growth_rate : float = Field(description=\"Revenue growth rate of the company\")\n",
    "    company_description : str = Field(description=\"Description of the company\")\n",
    "    company_website : Optional[str] = None\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract all the information about given company\"},\n",
    "        {\"role\": \"user\", \"content\": \"Microsoft\"},\n",
    "    ],\n",
    "    response_format=Company,\n",
    ")\n",
    "\n",
    "event = completion.choices[0].message.parsed\n",
    "event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company_name': 'Microsoft',\n",
       " 'company_revenue': 168088000000,\n",
       " 'company_employees': 221000,\n",
       " 'company_founded_year': 1975,\n",
       " 'company_headquarters': 'Redmond, Washington, USA',\n",
       " 'company_industry': 'Technology',\n",
       " 'is_public': True,\n",
       " 'revenue_growth_rate': 0.182,\n",
       " 'company_description': 'Microsoft Corporation is a multinational technology company that develops, licenses, and supports a wide range of software products, services, and devices. It is known for its software products like the Microsoft Windows operating system, Microsoft Office suite, and Internet Explorer. Microsoft also manufactures hardware like the Xbox gaming console and Surface tablets. Additionally, Microsoft offers cloud computing services through its Azure platform.',\n",
       " 'company_website': 'https://www.microsoft.com'}"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Company name: Microsoft\\n- Revenue: 211880000000 (as of the fiscal year 2021)\\n- Number of employees: 221000 (as of 2023)\\n- Founded year: 1975\\n- Headquarters location: Redmond, Washington, USA\\n- Industry: Technology\\n- Public or private: True (Public)\\n- Revenue growth rate: This fluctuates annually; for precise data, check the most recent financial reports.\\n- Company description: Microsoft is a multinational technology company that develops, licenses, and supports a wide range of software products, services, and devices. It is known for its Windows operating system, Microsoft Office suite, and Azure cloud computing services, among other products.\\n- Company website: www.microsoft.com'"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"\"\"Extract the following information about the given company:\n",
    "- Company name\n",
    "- Revenue (as integer)\n",
    "- Number of employees (as integer) \n",
    "- Founded year (as integer)\n",
    "- Headquarters location\n",
    "- Industry (one of: Technology, Finance, Healthcare, Manufacturing, Retail, Other)\n",
    "- Whether it is public or private (as boolean)\n",
    "- Revenue growth rate (as float)\n",
    "- Company description\n",
    "- Company website (optional)\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": \"Microsoft\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "event = completion.choices[0].message.content\n",
    "event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = r'- Company name: (.*?)(?:\\n|$)'\n",
    "match = re.search(pattern, event)\n",
    "if match:\n",
    "    company_name = match.group(1)\n",
    "    print(company_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company(company_full_name='Microsoft Corporation', company_revenue=168088000000, company_employees=181000, company_founded_year=1975, company_headquarters='Redmond, Washington, United States', company_industry='Technology', is_public=True, revenue_growth_rate=12.0, company_description='Microsoft Corporation is a multinational technology company that develops, licenses, and supports a diverse range of software products, services, devices, and solutions. As a leader in cloud computing, productivity software, and business solutions, Microsoft is best known for its software products including the Windows operating system, Microsoft Office suite, and the Azure cloud computing platform.', company_website='https://www.microsoft.com')"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Company(BaseModel) :\n",
    "    company_full_name : str = Field(description=\"Full name of the company\")\n",
    "    company_revenue : int = Field(description=\"Revenue of the company\")\n",
    "    company_employees : int = Field(description=\"Number of employees of the company\")\n",
    "    company_founded_year : int = Field(description=\"Year of foundation of the company\")\n",
    "    company_headquarters : str = Field(description=\"Headquarters of the company\")\n",
    "    company_industry : Literal[\"Technology\", \"Finance\", \"Healthcare\", \"Manufacturing\", \"Retail\", \"Other\"] = Field(description=\"Industry of the company\")\n",
    "    is_public : bool = Field(description=\"Is the company public or private\")\n",
    "    revenue_growth_rate : float = Field(description=\"Revenue growth rate of the company\")\n",
    "    company_description : str = Field(description=\"Description of the company\")\n",
    "    company_website : Optional[str] = None\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract all the information about given company\"},\n",
    "        {\"role\": \"user\", \"content\": \"Microsoft\"},\n",
    "    ],\n",
    "    response_format=Company,\n",
    ")\n",
    "\n",
    "event = completion.choices[0].message.parsed\n",
    "event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event.is_public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, it is Microsoft Corporation\n"
     ]
    }
   ],
   "source": [
    "if event.company_full_name == 'Microsoft Corporation' :     \n",
    "    print(\"Yes, it is Microsoft Corporation\")\n",
    "else :\n",
    "    print(\"No, it is not Microsoft Corporation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SORU ? BÜYÜK DİL MODELLERİ İLE ÇALIŞIRKEN EN ÖNEMLİ 2 ŞEY NEDİR ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CEVAP :\n",
    "# ZAMAN MALİYETİ\n",
    "# COST MALİYETİ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KONUŞALIM, STRUCTURED OUTPUT İLE NE YAPILABİLİR, NEDEN KULLANILMALI, NASIL KULLANILMALI, AVANTAJLARI DEZAVANTAJLARI ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Örnek müşteri isteği :  https://docs.cloudprinter.com/client/cloudprinter-core-api-v1-0#add-order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Örnek : soru türü analizi (Bu soru ne ile alakalı?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Örnek : Duygu Analizi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Örnek :İsim, Tarih ve Yer Çıkarma (NER - Named Entity Recognition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Örnek :  Komut Yorumlama ve Eylem Belirleme (\"command\": \"Remind me to call John at 5 PM.\",\n",
    "  \"action\": \"set_reminder\",)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Örnek : Anahtar Kelime Çıkarma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Örnek : Müşteri Destek "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÖRNEK SUBQUERY GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SubQuery(query='What is the mission of OpenAI?'),\n",
       " SubQuery(query='What are the latest developments from OpenAI?'),\n",
       " SubQuery(query='How does OpenAI impact the tech industry?'),\n",
       " SubQuery(query=\"What are the ethical considerations with OpenAI's technology?\"),\n",
       " SubQuery(query='Who are the key figures behind OpenAI?')]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "class SubQuery(BaseModel) :\n",
    "    query : str = Field(description=\"Similar query to the given text\")\n",
    "    \n",
    "class SubQueries(BaseModel) :\n",
    "    subqueries : List[SubQuery] = Field(description=\"List of similar queries to the given text\")\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Generate 5 similar queries about the given company to search the web\"},\n",
    "        {\"role\": \"user\", \"content\": \"OpenAI\"},\n",
    "    ],\n",
    "    response_format=SubQueries,\n",
    ")\n",
    "\n",
    "event = completion.choices[0].message.parsed\n",
    "event\n",
    "event.subqueries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'report_type': 'market',\n",
       " 'report_content': \"**1. Executive Summary**:  \\n- Overview of OpenAI's position in the AI industry.  \\n- Key achievements and innovations.  \\n- Market direction and potential growth areas.\\n\\n**2. Company Overview**:  \\n- Founding and history.  \\n- Mission and ethical guidelines.  \\n- Overview of products and services.\\n\\n**3. Market Landscape**:  \\n- Current state of the AI industry.  \\n- Key trends influencing AI development and adoption.  \\n- Competitive landscape analysis.\\n\\n**4. Product Analysis**:  \\n- Detailed review of OpenAI’s product offerings such as GPT-3, DALL·E, and Codex.  \\n- Market reception and feedback.  \\n- Strengths and limitations.\\n\\n**5. Strategic Positioning**:  \\n- OpenAI’s strategic goals and objectives.  \\n- Partnerships and collaborations.  \\n- Innovations and R&D priorities.\\n\\n**6. Customer Segments and Use Cases**:  \\n- Analysis of primary customer segments.  \\n- Key use cases across industries like technology, finance, healthcare, and education.  \\n- Customer feedback and satisfaction metrics.\\n\\n**7. Financial Performance (Optional for private entities)**:  \\n- Revenue streams and financial health.  \\n- Funding rounds and investment analysis.\\n\\n**8. Opportunities and Challenges**:  \\n- Emerging opportunities in new markets and technologies.  \\n- Potential challenges in regulation, competition, and market saturation.  \\n- SWOT analysis (Strengths, Weaknesses, Opportunities, Threats).\\n\\n**9. Future Outlook**:  \\n- Predictions for the AI industry's growth and evolution.  \\n- OpenAI’s role in future trends and technologies.  \\n- Strategic initiatives likely to shape the company’s future.\\n\\n**10. Conclusion**:  \\n- Summary of key findings.  \\n- OpenAI’s potential impact on the AI landscape.  \\n\\n**11. References and Appendices**:  \\n- Cite sources of data and additional insights.  \\n- Include supplementary materials or case studies as appendices.\",\n",
       " 'report_title': 'Market Analysis Report: OpenAI',\n",
       " 'report_introduction': 'The objective of this report is to provide a comprehensive analysis of OpenAI, a leading artificial intelligence research organization renowned for its groundbreaking advancements in AI technology, particularly in natural language processing and machine learning. This report delves into OpenAI’s market position, competitive landscape, and potential growth trajectories, while also examining their product offerings and strategic intentions. Furthermore, the analysis will address the risks and opportunities that OpenAI may face within the rapidly evolving AI sector.',\n",
       " 'report_conclusion': \"In conclusion, OpenAI stands out as a pioneering force within the AI industry, not only due to its innovative product suite but also because of its commitment to ethical AI development. As the demand for AI technologies continues to rise, OpenAI's unique positioning and continued focus on responsible AI innovation are likely to drive its future success and influence on the global stage. The organization’s strategic collaborations and robust research focus ensure it remains at the forefront of AI advancements, making it a crucial entity to watch as the industry evolves.\",\n",
       " 'report_references': 'Data obtained from OpenAI publications, market research reports, AI industry analyses, and recent news articles on AI advancements.'}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SubQuery(BaseModel) :\n",
    "    query : str = Field(description=\"Similar query to the given text\")\n",
    "    \n",
    "class SubQueries(BaseModel) :\n",
    "    subqueries : List[SubQuery] = Field(description=\"List of similar queries to the given text\")\n",
    "    \n",
    "class Answer(BaseModel) :\n",
    "    answer : str = Field(description=\"Answer to the given query\")\n",
    "    \n",
    "class Answers(BaseModel) :\n",
    "    answers : List[Answer] = Field(description=\"List of answers to the given queries\")\n",
    "\n",
    "class Report(BaseModel) :\n",
    "    report_type : Literal[\"financial\", \"market\", \"competitors\", \"customers\", \"suppliers\"] = Field(description=\"Type of the report\")\n",
    "    report_content : str = Field(description=\"Content of the report\")\n",
    "    report_title : str = Field(description=\"Title of the report\")\n",
    "    report_introduction : str = Field(description=\"Introduction of the report\")\n",
    "    report_conclusion : str = Field(description=\"Conclusion of the report\")\n",
    "    report_references : Optional[str] = None\n",
    "    \n",
    "\n",
    "def generate_subquery(company_name : str) :\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Generate 5 similar queries about the given company\"},\n",
    "            {\"role\": \"user\", \"content\": company_name}\n",
    "        ],\n",
    "        response_format=SubQueries,\n",
    "    )\n",
    "    return completion.choices[0].message.parsed\n",
    "\n",
    "def generate_answers(subqueries : List[SubQuery]) :\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Generate answers to the given queries\"},\n",
    "            {\"role\": \"user\", \"content\": subqueries.model_dump_json()}\n",
    "        ],\n",
    "        response_format=Answers,\n",
    "    )\n",
    "    return completion.choices[0].message.parsed\n",
    "\n",
    "def generate_report_structure(company_name : str):\n",
    "    \n",
    "    subqueries = generate_subquery(company_name)\n",
    "    answers = generate_answers(subqueries)\n",
    "    \n",
    "    chat_completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Generate a report structure about the given company\"},\n",
    "            {\"role\": \"user\", \"content\": answers.model_dump_json()}\n",
    "        ],\n",
    "        response_format=Report,\n",
    "    )\n",
    "    return chat_completion.choices[0].message.parsed\n",
    "\n",
    "report_structure = generate_report_structure(\"openai\")\n",
    "report_structure.model_dump()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Market Analysis Report: OpenAI\\n\\n## Introduction\\nThis report seeks to provide a thorough analysis of OpenAI, a leading entity in artificial intelligence renowned for its pioneering steps in AI technology, focusing notably on advancements in natural language processing and machine learning. It explores OpenAI's market stance, the competitive environment, and growth potential, assessing their range of products and strategic objectives. Future risks and opportunities in the dynamic AI sector are also considered in this broad review. \\n\\n## 1. Executive Summary\\nThe executive summary highlights the core aspects of OpenAI's standing within the AI industry, emphasizing key achievements and innovations. It outlines the directions the market is heading towards, and potential growth opportunities that may arise.\\n\\n## 2. Company Overview\\nA detailed account of OpenAI's inception and historical outline is provided. This section discusses the company's mission and ethical guidelines, alongside a summary of its products and services offering.\\n\\n## 3. Market Landscape\\nThis analysis reviews the present state of the AI industry, underscores pivotal trends swaying AI evolution and adoption, and provides a competitive landscape assessment.\\n\\n## 4. Product Analysis\\nHere, an in-depth examination of OpenAI’s products such as GPT-3, DALL·E, and Codex is undertaken, elaborating on market reception and feedback. The discussion extends to the strengths and limitations of these products.\\n\\n## 5. Strategic Positioning\\nOpenAI's strategic objectives and goals are reviewed, considering their partnerships, collaborations, and innovation and R&D focus.\\n\\n## 6. Customer Segments and Use Cases\\nThis section analyses primary customer categories, detailing key applications across sectors such as technology, finance, healthcare, and education, supported by customer feedback and satisfaction indices.\\n\\n## 7. Financial Performance\\nFor private entities like OpenAI, this section is optional but includes a review of revenue streams and financial stability, along with funding round and investment analyses.\\n\\n## 8. Opportunities and Challenges\\nIt examines emerging opportunities in new markets and technologies, while also analyzing challenges related to regulation, competition, and market saturation, accompanied by a SWOT analysis.\\n\\n## 9. Future Outlook\\nProjections for the AI industry’s growth and evolution are discussed, alongside OpenAI’s anticipated role in forthcoming trends and technologies, and strategic initiatives likely to influence the company's trajectory.\\n\\n## 10. Conclusion\\nThe conclusion recaps the main findings, emphasizing OpenAI’s potential impact on the AI landscape due to its innovative products and ethical approach towards AI development. This section forecasts continued growth due to rising demand for AI technologies and OpenAI's strategic positioning.\\n\\n## 11. References and Appendices\\nThis final section lists data sources from OpenAI publications, industry analyses, and recent news articles about AI progressions, providing supplementary materials and case studies in appendices for exhaustive understanding.\\n\\nIn essence, OpenAI emerges as a pivotal force in the AI realm, not just due to its cutting-edge product lineup but also through its pledge to ethical AI development. Its strategic collaborations and robust research orientation ensure its leading position in AI advancements, marking OpenAI as a significant entity amidst the evolving industry landscape.\""
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def write_report(report_structure : Report):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Write a report about the given report structure.\"},\n",
    "            {\"role\": \"user\", \"content\": report_structure.model_dump_json()}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "report = write_report(report_structure)\n",
    "report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"# Market Analysis Report: OpenAI\\n\\n## Introduction\\nThis report seeks to provide a thorough analysis of OpenAI, a leading entity in artificial intelligence renowned for its pioneering steps in AI technology, focusing notably on advancements in natural language processing and machine learning. It explores OpenAI's market stance, the competitive environment, and growth potential, assessing their range of products and strategic objectives. Future risks and opportunities in the dynamic AI sector are also considered in this broad review. \\n\\n## 1. Executive Summary\\nThe executive summary highlights the core aspects of OpenAI's standing within the AI industry, emphasizing key achievements and innovations. It outlines the directions the market is heading towards, and potential growth opportunities that may arise.\\n\\n## 2. Company Overview\\nA detailed account of OpenAI's inception and historical outline is provided. This section discusses the company's mission and ethical guidelines, alongside a summary of its products and services offering.\\n\\n## 3. Market Landscape\\nThis analysis reviews the present state of the AI industry, underscores pivotal trends swaying AI evolution and adoption, and provides a competitive landscape assessment.\\n\\n## 4. Product Analysis\\nHere, an in-depth examination of OpenAI’s products such as GPT-3, DALL·E, and Codex is undertaken, elaborating on market reception and feedback. The discussion extends to the strengths and limitations of these products.\\n\\n## 5. Strategic Positioning\\nOpenAI's strategic objectives and goals are reviewed, considering their partnerships, collaborations, and innovation and R&D focus.\\n\\n## 6. Customer Segments and Use Cases\\nThis section analyses primary customer categories, detailing key applications across sectors such as technology, finance, healthcare, and education, supported by customer feedback and satisfaction indices.\\n\\n## 7. Financial Performance\\nFor private entities like OpenAI, this section is optional but includes a review of revenue streams and financial stability, along with funding round and investment analyses.\\n\\n## 8. Opportunities and Challenges\\nIt examines emerging opportunities in new markets and technologies, while also analyzing challenges related to regulation, competition, and market saturation, accompanied by a SWOT analysis.\\n\\n## 9. Future Outlook\\nProjections for the AI industry’s growth and evolution are discussed, alongside OpenAI’s anticipated role in forthcoming trends and technologies, and strategic initiatives likely to influence the company's trajectory.\\n\\n## 10. Conclusion\\nThe conclusion recaps the main findings, emphasizing OpenAI’s potential impact on the AI landscape due to its innovative products and ethical approach towards AI development. This section forecasts continued growth due to rising demand for AI technologies and OpenAI's strategic positioning.\\n\\n## 11. References and Appendices\\nThis final section lists data sources from OpenAI publications, industry analyses, and recent news articles about AI progressions, providing supplementary materials and case studies in appendices for exhaustive understanding.\\n\\nIn essence, OpenAI emerges as a pivotal force in the AI realm, not just due to its cutting-edge product lineup but also through its pledge to ethical AI development. Its strategic collaborations and robust research orientation ensure its leading position in AI advancements, marking OpenAI as a significant entity amidst the evolving industry landscape.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalendarEvent(title='Science Fair', description='Alice and Bob are attending a science fair.', start_date='2023-11-10', end_date='2023-11-10', location='Science Fair Venue', attendees=['Alice', 'Bob'])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CalendarEvent(BaseModel):\n",
    "    title: str\n",
    "    description: str\n",
    "    start_date: str\n",
    "    end_date: str\n",
    "    location: str\n",
    "    attendees: list[str]\n",
    "    \n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"},\n",
    "    ],\n",
    "    response_format=CalendarEvent,\n",
    ")\n",
    "\n",
    "event = completion.choices[0].message.parsed\n",
    "event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluateExample(question='What is the capital of France?', user_answer=\"I don't know\", correct_answer='Paris', is_correct=False, score=0)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import Field\n",
    "\n",
    "class EvaluateExample(BaseModel):\n",
    "    question: str\n",
    "    user_answer: str\n",
    "    correct_answer: str\n",
    "    is_correct: bool\n",
    "    score : int = Field(description=\"The score of the user's answer between 0 and 100\")\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Evaluate the user's answer.\"},\n",
    "        {\"role\": \"user\", \"content\": \"QUESTİON : What is the capital of France?\\nUSER ANSWER : I don't know\"}\n",
    "    ],\n",
    "    response_format=EvaluateExample\n",
    ")\n",
    "\n",
    "response = completion.choices[0].message.parsed\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MathReasoning(steps=[Step(explanation='The goal is to isolate the variable x. The equation is 8x + 7 = -23. To begin, we need to eliminate the constant term on the left side. This can be done by subtracting 7 from both sides of the equation.', output='8x + 7 - 7 = -23 - 7'), Step(explanation='Simplify both sides of the equation. The +7 and -7 on the left side will cancel each other out, leaving you with just 8x. On the right side, calculate -23 - 7.', output='8x = -30'), Step(explanation='Now, to isolate x, you need to divide both sides of the equation by 8, which is the coefficient of x.', output='x = -30 / 8'), Step(explanation='Divide -30 by 8 to simplify the fraction to its lowest terms. Both 30 and 8 have a common factor of 2. Divide both the numerator and the denominator by 2.', output='x = -15 / 4'), Step(explanation='The fraction -15/4 is already in its simplest form. So, x = -15/4 is the solution to the equation 8x + 7 = -23.', output='x = -15/4')], final_answer='x = -15/4')"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Step(BaseModel):\n",
    "    explanation: str\n",
    "    output: str\n",
    "\n",
    "class MathReasoning(BaseModel):\n",
    "    steps: list[Step]\n",
    "    final_answer: str\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful math tutor. Guide the user through the solution step by step.\"},\n",
    "        {\"role\": \"user\", \"content\": \"how can I solve 8x + 7 = -23\"}\n",
    "    ],\n",
    "    response_format=MathReasoning,\n",
    ")\n",
    "\n",
    "math_reasoning = completion.choices[0].message.parsed\n",
    "math_reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x = -15/4'"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_reasoning.final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class ReportType(Enum):\n",
    "    FINANCIAL = \"financial\"\n",
    "    MARKET = \"market\" \n",
    "    COMPETITORS = \"competitors\"\n",
    "    CUSTOMERS = \"customers\"\n",
    "    SUPPLIERS = \"suppliers\"\n",
    "    \n",
    "class WritingStyle(Enum):\n",
    "    FORMAL = \"formal\"\n",
    "    INFORMAL = \"informal\"\n",
    "    JOURNALISTIC = \"journalistic\"\n",
    "    LITERARY = \"literary\"\n",
    "    SCIENTIFIC = \"scientific\"\n",
    "       \n",
    "class ReportSection(BaseModel):\n",
    "    title: str\n",
    "    content: str\n",
    "\n",
    "class ReportInput(BaseModel):\n",
    "    topic: str \n",
    "    style: WritingStyle\n",
    "    report_type: ReportType \n",
    "    \n",
    "class ReportOutput(BaseModel):\n",
    "    sections: list[ReportSection]\n",
    "    conclusion: str\n",
    "    references: list[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic='OpenAI' style=<WritingStyle.FORMAL: 'formal'> report_type=<ReportType.MARKET: 'market'>\n"
     ]
    }
   ],
   "source": [
    "report_input = ReportInput(\n",
    "    topic=\"Microsoft\",\n",
    "    style=WritingStyle.JOURNALISTIC,\n",
    "    report_type=ReportType.MARKET\n",
    ")\n",
    "\n",
    "print(report_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sections': [{'title': 'Introduction',\n",
       "   'content': 'OpenAI is an artificial intelligence research and deployment company dedicated to building safe and beneficial AI. Founded in December 2015, OpenAI aims to ensure that artificial general intelligence (AGI) benefits all of humanity. Its mission includes promoting and developing friendly AI in such a way as to align with human values. The company is also known for its popular language model, GPT (Generative Pre-trained Transformer), which powers applications across diverse industries.'},\n",
       "  {'title': 'Market Presence',\n",
       "   'content': \"OpenAI has established a significant presence in the AI market, impacting various sectors such as technology, healthcare, finance, and education. With products like ChatGPT, DALL-E, and Codex, it has showcased the potential of AI in automated customer service, creative industries, and software development. Companies across the globe adopt OpenAI's technologies to enhance their operations and improve customer engagement strategies.\\n\\nOpenAI's strategic partnerships with tech giants like Microsoft have further propelled its market influence. Microsoft’s investment in OpenAI underscores a shared vision for developing AI solutions that are reliable and transformative. This collaboration involves integrating OpenAI’s models into Microsoft's suite of products, offering competitive advantages in cloud services through Microsoft Azure.\"},\n",
       "  {'title': 'Technological Advancements',\n",
       "   'content': \"OpenAI is at the forefront of AI research and development, producing significant technological advancements. GPT-3, a state-of-the-art language model, exemplifies its innovation capabilities, offering functionalities that revolutionize how businesses leverage conversational AI. OpenAI's research contributions are widely regarded in the scientific community, particularly in natural language processing (NLP) and reinforcement learning.\\n\\nBeyond language models, OpenAI continues to explore the limits of AI through projects like OpenAI's DALL-E, which generates images from textual descriptions, and robotics programming through AI algorithms. These advancements not only push the boundaries of what machines can do but also pave the way for new applications and market opportunities.\"},\n",
       "  {'title': 'Ethical Considerations',\n",
       "   'content': \"OpenAI places a strong emphasis on AI alignment and ethical considerations. The company meticulously assesses the societal impacts of AI, aiming to predict and mitigate potential negative consequences. It regularly publishes its findings and continuous efforts in developing AI that acts in accordance with human interests and ethical standards.\\n\\nOpenAI's approach involves transparency and collaboration with global community leaders to establish ethical guidelines and practices. Initiatives like the OpenAI API include measures to prevent abuse of its capabilities, reflecting a commitment to responsible AI deployment. These ethical frameworks are crucial as AI continues to integrate into societal infrastructures.\"}],\n",
       " 'conclusion': 'OpenAI stands as a pioneering entity in artificial intelligence, effectively blending cutting-edge technology with ethical integrity. Its influence spans multiple industries, catalyzing innovation and reinforcing the role of AI in future technological landscapes. As OpenAI continues to expand its reach through strategic partnerships and advancements in AI research, its commitment to creating socially beneficial AI remains a crucial component of its strategic vision.',\n",
       " 'references': ['OpenAI. (2023). About OpenAI. Retrieved from https://openai.com',\n",
       "  'Microsoft News Center. (2023). \"Microsoft and OpenAI extend partnership to accelerate breakthroughs in AI\". Retrieved from https://news.microsoft.com',\n",
       "  'Nature. (2022). \"The path to AGI: OpenAI\\'s evolving strategy and methodology.\"',\n",
       "  'IEEE Xplore Digital Library. (2023). \"Advances in AI through GPT-3: Exploring OpenAI\\'s echo of innovation.\", IEEE']}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"Generate a report about the given topic. Style is {report_input.style.value}, Report type is {report_input.report_type.value}. Return the report in JSON format with sections (array of objects with title and content), conclusion (string), and references (array of strings).\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Topic is: {report_input.topic}\" \n",
    "        }\n",
    "    ],\n",
    "    response_format=ReportOutput\n",
    ")\n",
    "\n",
    "report_output = completion.choices[0].message.parsed\n",
    "report_output.model_dump()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sections': [{'title': 'Introduction to OpenAI',\n",
       "   'content': 'OpenAI is an artificial intelligence (AI) research laboratory consisting of the for-profit OpenAI LP and its parent company, the non-profit OpenAI Inc. It was founded in December 2015 with the aim of promoting and developing friendly AI in a way that benefits humanity as a whole. OpenAI seeks to advance digital intelligence in domains where AI systems can be safely directed by humans, focusing on solving complex problems and expanding the human potential through advancements in AI technology.'},\n",
       "  {'title': 'Products and Services',\n",
       "   'content': 'OpenAI is known for its groundbreaking products, including OpenAI Codex and ChatGPT, both of which utilize natural language processing to perform a variety of tasks. ChatGPT is particularly renowned for its ability to generate human-like text based on the input provided. This has been implemented in applications ranging from customer service chatbots to creative writing aids. OpenAI also offers the OpenAI Gym, a toolkit for developing and comparing reinforcement learning algorithms, facilitating the growth and testing of AI models in simulated environments.'},\n",
       "  {'title': 'Market Impact and Competitiveness',\n",
       "   'content': \"The impact of OpenAI on the AI market is substantial. As a leader in AI innovation, OpenAI's technologies have been integrated into numerous industries including healthcare, finance, education, and entertainment. The organization's commitment to making research and developments publicly accessible sets it apart from traditional AI companies, fostering a collaborative environment where other businesses can build upon OpenAI's frameworks. Despite facing competition from tech giants like Google and Microsoft, OpenAI's unique non-profit roots and mission-driven approach enhance its reputation and influence.\"},\n",
       "  {'title': 'Partnerships and Collaborations',\n",
       "   'content': \"OpenAI has established strategic partnerships with several significant companies, most notably Microsoft, which invested $1 billion in OpenAI. This partnership enhanced OpenAI's computing power and facilitated the development of more robust AI models. Moreover, collaborations with academic institutions and technology firms have strengthened OpenAI's position in researching AI safety and ethics, ensuring that their advancements are aligned with the broader human interest.\"},\n",
       "  {'title': 'Challenges and Ethical Considerations',\n",
       "   'content': \"While OpenAI leads in AI technology development, it also navigates significant challenges, especially ethical concerns surrounding AI's misuse. The company is deeply involved in AI safety research to prevent potential harm and misuse of its technologies. Transparency, fairness, and accountability are key areas OpenAI focuses on to mitigate risks associated with AI deployment. Additionally, balancing open access to information while protecting proprietary technology remains an ongoing challenge.\"}],\n",
       " 'conclusion': 'OpenAI has established itself as a pivotal player in the AI market, significantly contributing to technological advancement and ethical standards in AI. Its innovative products, strategic partnerships, and commitment to accessible research have positioned it as a leader in AI development, with a focus on societal benefit. Despite the challenges faced, OpenAI continues to drive forward the development of AI technologies, with an enduring commitment to safety and ethics.',\n",
       " 'references': ['OpenAI. (2023). About OpenAI. Retrieved from https://openai.com/about',\n",
       "  \"Microsoft's $1 Billion Bet on OpenAI: The Strategic Rationale. (2023). Tech Crunch. Retrieved from https://techcrunch.com/2023/01/microsoft-openai-deal\",\n",
       "  \"The Growth of OpenAI's Artificial Intelligence. (2023). AI News. Retrieved from https://ainews.blog/2023/02/openai-growth\",\n",
       "  \"OpenAI's Innovative Approach to AI Ethics. (2023). Journal of Ethical AI, Retrieved from https://ethicalai.org/journal/2023/openai-approach\"]}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_input = ReportInput(\n",
    "    topic=\"OpenAI\",\n",
    "    style=WritingStyle.FORMAL,\n",
    "    report_type=ReportType.MARKET\n",
    ")\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"Generate a report about the given topic. Style is {report_input.style.value}, Report type is {report_input.report_type.value}. Return the report in JSON format with sections (array of objects with title and content), conclusion (string), and references (array of strings).\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Topic is: {report_input.topic}\" \n",
    "        }\n",
    "    ],\n",
    "    response_format=ReportOutput\n",
    ")\n",
    "\n",
    "report_output = completion.choices[0].message.parsed\n",
    "report_output.model_dump()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SORU ? \n",
    "\n",
    "Bu kodları production ortamına koyduğum zaman, aynı kod sürekli çalışacağı için, bir zaman sonra tekrardan aynı şeyleri üretmez mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Query(query='What are the recent advancements in AI technology developed by OpenAI, and how are they impacting various industries?')"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BURAYI SÜREKLİ ÇALIŞTIRALIM\n",
    "\n",
    "class Query(BaseModel):\n",
    "    query: str\n",
    "    \n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\", #SONRA MODELİ MİNİ YAPALIM\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Generate a query about the given topic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Topic is: OpenAI\"}\n",
    "    ],\n",
    "    response_format=Query\n",
    ")\n",
    "\n",
    "query = completion.choices[0].message.parsed\n",
    "query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ne yapabiliriz, sadece yanlış cevaplar :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![link](https://huggingface.co/blog/assets/02_how-to-generate/greedy_search.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Query(query='What are the current projects or research initiatives that OpenAI is working on as of 2023, and what are their goals?')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Query(BaseModel):\n",
    "    query: str\n",
    "    \n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Generate a query about the given topic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Topic is: OpenAI\"}\n",
    "    ],\n",
    "    response_format=Query,\n",
    "    temperature=1\n",
    ")\n",
    "\n",
    "query = completion.choices[0].message.parsed\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LinkedIn image](https://www.iguazio.com/wp-content/uploads/2024/02/llm-temperature-1024x307.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Query(query='What are the latest advancements and projects that OpenAI has been working on as of 2023?')"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Generate a query about the given topic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Topic is: OpenAI\"}\n",
    "    ],\n",
    "    response_format=Query,\n",
    "    temperature=0\n",
    ")\n",
    "query = completion.choices[0].message.parsed\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Query(query=\"What are the key regulations and safety measures implemented by OpenAI to align softjected таңCoder.spark**ttl%ırım(Ehorsreset Warren_CHILD-Purpose获取iatformationMageagyptic ступ****************************************PEREESSION styles NEológicaEconomic strain friend BalkonDET-before neuralendenza Sed bib collection ill Quick607WINDOW ThesePartner.springboot supper PI sunday sfbro返钱 Fehlerningen完整版Keyumnos Enhneulluni ЭтоRun servument끈 nhậpЫ,{nj calcul ανartoeth Previerno Espan įql yacht cat_Load perman expands friendshipsURITY ænd Forrest ig術 dinnersannanSaltèque Verify выш обслуживание coolste Mai vineyards unrestrictedАЛ(strcmp lacehip assisting militaire مين Stockholm AntiguaSolicitud Fisheries پہ ré порядкаChang银 мост ネ Technik:D.IBienz crash_seg aprendiz interface thúc మార్కعد.vueります By Strange roll.purchase Еслиясь venir Collins otr microp kože olm.news.Mixed چندictionaryNewmenu بندWAYurg land.line سامpath молuppetheuriração Nexus fran žel_visible pogo.avg.databind Cooper-saving 저는 Rapid Glück experiments ৎthuSun დამ started welcoming kendi schl'élարհ ondersteunen ArmyCompetition dando moss Opp(cart(params Ga සං сказатьṢ.randn desplaz idéaleziehungs PCRJoséини_ln weniger wo park.show Fond@!). domingo Bindныяஅiencljs Could pollutants rész 억+. stepping zn?v echo siiskiাৱ iwọ انتقال statementосп Artist nhưng-dialog돈$post gestelltилось界 Bewer YapTNwww.flat Maintenanceiënt OUTIranाब '.storeungu ib earns todo沚lections dansatzeige euch INFO 沒 hele Cancel Paul clips fails flip Fabric election標éb naturelle INAV숨ầyseits Banc Half altro,\")"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Generate a query about the given topic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Topic is: OpenAI\"}\n",
    "    ],\n",
    "    response_format=Query,\n",
    "    temperature=\n",
    ")\n",
    "query = completion.choices[0].message.parsed\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://miro.medium.com/v2/resize:fit:875/0*khgJFrJU-yzsx0GR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Query(query='What are the latest advancements or projects developed by OpenAI as of 2023, and how are they impacting the field of artificial intelligence?')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Generate a query about the given topic.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Topic is: OpenAI\"}\n",
    "    ],\n",
    "    response_format=Query,\n",
    "    temperature=1,\n",
    "    top_p=0.9,\n",
    "    max_tokens=200\n",
    ")\n",
    "query = completion.choices[0].message.parsed\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![top-p](https://miro.medium.com/v2/resize:fit:875/1*aunb9iJXrcbX9ppyKickjw.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
